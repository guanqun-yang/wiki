================
Machine Learning
================

:Author: Guanqun Yang


.. role:: raw-latex(raw)
   :format: latex
..

Preface
=======

The following notes come from three major sources

-  School course: This is the most important source of information,
   without which I probably still do random search in a *nearly*
   infinite "learning space". Each of these courses marks the milestone
   of my experiences of doing machine learning

   #. CM 146: Introduction to Machine Learning

      This is an introductory course of machine learning and it helps me
      build up a mental repo of numerous algorithms. Just as many other
      introductory courses, an algorithm-by-algorithm style teaching is
      used by instroctor.
   #. STAT 202A: Statistical Computing

      The computation and statistical side of machine learning is the
      emphasis, both of which are largely negelected even in advanced
      level courses. The instroctor, Prof. Ying-Nian Wu, could dive into
      low level computation or jump into very high level theoretical
      generalization in a snap. These insights are invaluable for me to
      organize my mental repo previously built.
   #. CS 260: Machine Learning Algorithms

      This is the course that answers some fundamental yet negelected
      questions like "why machine could learn" and "how well machine
      could learn". Even though it is a little mathematical intensive,
      the course equips me with a full set of tools to analyze machine
      learning algorithms in a structural fashion.

-  Self-study: The self-study of machine learning started from undergrad
   when I spent a lot of time doing mathematical modeling contests. Even
   though mathematical modeling is a *totally different* perspective to
   solve problems compared with machine learning, those experiences did
   get me exposed to some terms like neural network and SVM.

   Self-study never stops ever since then but now it becomes more
   productive with help of formal education I received.
-  Project experiences: Though this may not seem to be directly releated
   to this set of notes, doing projects for project-based course or
   Kaggle let me know the power of machine learning and motivated me to
   learn more, either from school courses or self-study.

Since most of the following sections will talk about specific
algorithms, they will be organized in a similar layout and common
components may inlucde ``Motivation``, ``Algorithm``, ``Discussion`` and
``Computation``. However, when discussing learning theory, such layouts
will not be followed. :raw-latex:`\\`

Learning Theory
===============

Introduction
------------

Just like :math:`(\epsilon,\delta)` definition of limit in calculus,
learning theory tries to answer the fundamental questions like "why
machine could learn" and therefore it serves as the very foundation of
machine learning.

:raw-latex:`\\`

Linear Regression
=================

:raw-latex:`\\`

Logistic Regression
===================
